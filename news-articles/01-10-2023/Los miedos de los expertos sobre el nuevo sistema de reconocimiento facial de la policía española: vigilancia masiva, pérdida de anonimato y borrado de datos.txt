Los miedos de los expertos sobre el nuevo sistema de reconocimiento facial de la policía española: vigilancia masiva, pérdida de anonimato y borrado de datos

Interior no disipa las dudas sobre los aspectos oscuros de la implantación de una herramienta llamada a revolucionar las labores policiales, que suscita dudas en torno a su transparencia, proporcionalidad y mecanismos de gobernanza

La Policía Nacional y la Guardia Civil empezará este año a usar un sistema automático de reconocimiento facial en sus investigaciones, tal y como adelantó EL PAÍS. Se trata de ABIS, una herramienta que emplea algoritmos de inteligencia artificial para determinar en pocos segundos si en una imagen cualquiera figura un rostro del que se tengan registros (en este caso, de personas con ficha policial). La tecnología ya está lista; solo falta completar la integración de la base de datos con la que se empezará a operar, según fuentes del Ministerio de Interior. En cuanto acabe este proceso, lo que se prevé que suceda en la primera mitad de 2023, se podrá empezar a utilizar este programa informático, que ha sido desarrollado por la empresa militar francesa Thales.

Pero su aplicación presenta varios interrogantes, especialmente relacionados con la transparencia y los mecanismos de control exigibles a herramientas que trabajan con datos biométricos. La propia Agencia Española de Protección de Datos (AEPD) lleva desde septiembre estudiando su encaje en el entramado legislativo, y deberá determinar si vulnera o no algún derecho.

Este periódico ha preguntado a Interior sobre los puntos oscuros o poco claros de ABIS, detectados con la ayuda de varios expertos, entre los que se encuentran dudas sobre su transparencia, la forma de compartir y gestionar las bases de datos o cómo se garantizará un uso proporcional del sistema. El Ministerio ha rehusado aportar información adicional clave para dispar esas dudas. Estas son las cuestiones que más preocupan a los ingenieros, analistas y activistas consultados.

El uso policial de tecnologías automáticas de reconocimiento facial es delicado porque estas permiten identificar inequívocamente a los individuos. El sistema es capaz de detectar los rostros humanos en imágenes digitalizadas, ya procedan de un móvil o de cámaras de seguridad, y de extraer un patrón único e inconfundible de los rasgos de cada persona, igual que sucede con las huellas dactilares o el ADN. Aunque hay una diferencia importante: mientras que en los dos últimos casos hace falta establecer contacto físico con el afectado (para extraerle las huellas o una muestra de saliva), con el reconocimiento facial se puede hacer todo a distancia.

Eso lo convierte en una tecnología perfecta para la vigilancia masiva. Pekín lo sabe desde hace años. Las calles de las grandes ciudades chinas están repletas de cámaras dotadas de estos sistemas. Las autoridades pueden localizar en minutos a cualquier ciudadano buscando su rostro en tiempo real. No hay escapatoria posible.

La UE prohíbe usar reconocimiento facial en tiempo real en espacios públicos. Interior descarta por completo usar ABIS para labores de vigilancia en vez de para investigaciones. Sin embargo, el Ministerio no aclara cómo ni quién va a controlar cómo se usa la herramienta. “Necesitamos saber cuántas veces se va a utilizar el sistema: ¿solo para casos de especial gravedad o para cualquier investigación? Si se generaliza su uso, se puede convertir en una herramienta de vigilancia masiva casi sin querer”, opina Carmela Troncoso, profesora de la Escuela Politécnica Federal de Lausana (Suiza) y autora del protocolo de rastreo seguro usado en las aplicaciones de rastreo de contagios de la covid.

La experta tiene dudas también sobre el anonimato que promete Thales respecto a la gestión de los datos biométricos de ABIS. “La información almacenada se fundamenta en datos alfanuméricos que imposibilitan la identificación del propietario de sus huellas”, explica la compañía francesa. El objetivo es que si alguien roba esa base de datos no pueda asociar los rostros ahí guardados con las identidades de los mismos.

“Esto es un poco dudoso. No porque las representaciones sean alfanuméricas significa que no se puedan reconstruir, porque hay evidencia de lo contrario: se pueden reconstruir imágenes a partir de los modelos. La pregunta es qué estudios se han hecho para fundamentar estas declaraciones”, abunda Troncoso.

Respecto al funcionamiento del algoritmo desarrollado por Thales, tanto la empresa como Interior aseguran que “ha pasado el Test de Vendedores de NIST”, una compañía independiente de ámbito no comercial. “Eso es como no decir nada”, replica Troncoso. “Tienen un baremo, pero no dicen si eso es bueno, malo o regular. ¿Cuál es la puntuación del algoritmo en ese test? ¿Es la adecuada para el caso de uso propuesto? ¿Quién se va a ocupar de comprobar que lo siga siendo con el paso del tiempo?”. Preguntado por este diario, Interior no ha respondido a estas cuestiones.

La otra gran preocupación que rodea el uso de esta tecnología es a quién se le aplicará. Según contó Interior a EL PAÍS, la base de datos contra la que se contrastarán las imágenes que se quieran examinar tiene unos cinco millones de reseñas fotográficas faciales de detenidos y sospechosos que ya estaban fichados por la Policía Nacional, la Guardia Civil y otros cuerpos autonómicos.

¿Durante cuánto tiempo queda registrado un sospechoso en la base de datos? ¿Qué sucede cuando un sospechoso deja de serlo, por ejemplo, por ser declarado inocente en un tribunal? ¿Se le elimina de la base de datos o permanece en ella? El Ministerio ha preferido no responder tampoco a estas preguntas. “Limpiar estas bases de datos va a ser un problema. Hace falta tenerlas actualizadas mediante intercambio con las bases de datos de otras instituciones envueltas en el proceso”, explica Lorena Jaume-Palasí, experta en ética y filosofía del Derecho aplicadas a la tecnología y asesora del Gobierno de España y del Parlamento Europeo para cuestiones relacionadas con la inteligencia artificial. Dicho de otro modo: el Ministerio de Interior debería estar coordinado con el de Justicia e intercambiar información, algo que no es la norma ni en este ni en otros países de nuestro entorno. “Aquí hay al menos dos problemas: por un lado, no tienes la infraestructura necesaria para poder desplegar el sistema a nivel nacional e internacional, y por otro, tienes un problema de enforcement entre instituciones que no cooperan”, añade la investigadora.

Permanecer en esa base de datos significa poder ser identificado como sospechoso en cualquier crimen. Porque los algoritmos fallan, y los agentes que examinan los candidatos que aporta ABIS en una búsqueda pueden equivocarse también.

Interior tiene intención de compartir los datos biométricos faciales que almacena con sus socios europeos. “El sistema ABIS de España puede conectarse con bases de datos comunitarias, como Eurodac, EU-Lisa o VIS”, explican fuentes de Thales. Según aseguró el Ministerio a este periódico, las bases de datos que maneje la policía estarán totalmente separadas de las civiles (por ejemplo, las que contienen las fotos del DNI). “Pero si el sistema ABIS se integra en EU-Lisa, lo hará con los solicitantes de asilo, que no han delinquido ni son criminales”, señala Javier Sánchez Monedero, investigador Beatriz Galindo en Inteligencia Artificial del departamento de Informática y Análisis Numérico de la Universidad de Córdoba.

La reciente reforma de Eurodac, la base de datos europea de huellas dactilares para identificar a los solicitantes de asilo y a los irregulares que cruzan la frontera, elimina la necesidad de tener orden judicial para que la policía pueda hacer una consulta. Si se guardan los registros faciales recogidos por las fuerzas de seguridad en esa misma base de datos, se podrá mirar automáticamente sin pasar por el juez. “Es importante entender cuáles son los límites y casuísticas del manejo de datos. Nuestra experiencia previa es que, una vez echan a andar estos sistemas, no paran de crecer”, añade.

La pregunta que se hacen muchos expertos es por qué necesitamos esta herramienta. ¿Se ha estudiado que los beneficios potenciales de la implantación de este sistema superarán a los posibles problemas que genere? Interior asegura que ABIS facilitará mucho el trabajo de la policía. Será capaz de identificar rápidamente a sospechosos en imágenes de la escena del crimen que, de otro modo, quizás no se podrían localizar.

Pero implantar un sistema automático de reconocimiento facial es más que eso. “No vas a hacer el proceso más eficiente, sino que vas a cambiar el proceso en sí”, resume Jaume-Palasí. “Harán falta buenos servidores, copias de seguridad, un montón de energía y reentrenar a los profesionales que trabajan con estos sistemas en la policía, entre otros. Son sistemas, además, que no pueden funcionar bien porque la idea de fondo, la metodología en sí, es mala. Identificar a personas en base a cualquier categoría biométrica siempre implica fallos, es necesario utilizar otros métodos y evaluar otros aspectos”.

“No hay un conjunto de algoritmos capaz de abarcar la multidimensionalidad necesaría para incluir todos los parámetros necesarios para identificar a alguien”, prosigue la experta en ética digital. “El proceso de identificación de una persona a partir de sus datos biométricos es un proceso ya de por sí problemático, basado en ideas eugénicas. El color de la piel, por ejemplo, es un continuo, no puedes dar un número concreto de categorías. Eso, a nivel técnico, es un problema, porque los sistemas necesitan acotar las variables. Y esta regla se aplica a gran cantidad de rasgos faciales, como la apertura de ojos y boca, tamaño y forma de la nariz, etcétera”, explica.

Cuanta más información delicada se acumule, mayor probabilidad de que se haga un mal uso de ella. “Creemos que realmente no hace falta recoger datos biométricos, ya que atenta contra derechos fundamentales y supone una violación de la privacidad”, sostiene Youssef M. Ouled, coordinador de AlgoRace, un colectivo que investiga las consecuencias del uso racista de la inteligencia artificial. “Hay un enorme vacío de datos sobre estos sistemas, que no se auditan. Apuestan por la securitización, van en dirección contraria a lo que la sociedad civil está demandando. Y tienen que ver con la obsesión del Estado de tener muchos datos sobre nosotros sin que sepamos muy bien qué van a hacer con ellos”, abunda.

“Esta tecnología tiene un potencial enorme para ser algo peligroso, y no sabemos cuál es su potencial real para ser beneficioso”, zanja Troncoso. “No tenemos ninguna garantía de que no vaya a tener malas consecuencias. Se nos justifica su uso en aras de la eficiencia, pero ¿qué o cuánto vamos a ganar? ¿Tenemos algún tipo de evidencia al respecto? Estamos hablando de implantar una tecnología que aplica a todos los españoles, de la que no puedes decidir no participar y con la que tampoco sabemos si ganamos o perdemos”.

Puedes seguir a EL PAÍS TECNOLOGÍA en Facebook y Twitter o apuntarte aquí para recibir nuestra newsletter semanal.

